# Task ID: 9
# Title: Implement Landing Page Scraping Module
# Status: pending
# Dependencies: 3, 4
# Priority: medium
# Description: Create module to scrape competitor landing pages using FireCrawl API and extract copy insights
# Details:
1. Create processors/landing_page_scraper.py with the following functionality:

```python
from src.api_integration.firecrawl import FireCrawlClient
from src.data_models import ScrapedCopy
import re
import logging

class LandingPageScraper:
    def __init__(self, firecrawl_client):
        self.firecrawl_client = firecrawl_client
    
    def scrape_landing_pages(self, urls):
        """Scrape landing pages using FireCrawl API"""
        scraped_data = []
        
        for url in urls:
            try:
                # Get page content from FireCrawl
                page_content = self.firecrawl_client.scrape_url(url)
                
                # Extract relevant content
                scraped_copy = self._extract_copy(url, page_content)
                scraped_data.append(scraped_copy)
                
            except Exception as e:
                logging.error(f"Error scraping URL '{url}': {e}")
                # Add empty record to maintain URL in output
                scraped_data.append(ScrapedCopy(url=url))
        
        return scraped_data
    
    def _extract_copy(self, url, page_content):
        """Extract headlines, CTAs, and body text from page content"""
        # Extract headline (usually in h1 tag)
        headline_match = re.search(r'<h1[^>]*>(.*?)</h1>', page_content, re.DOTALL)
        headline = self._clean_text(headline_match.group(1)) if headline_match else None
        
        # Extract CTA (buttons, forms, etc.)
        cta_matches = re.findall(r'<button[^>]*>(.*?)</button>|<input[^>]*type=["\']submit["\'][^>]*value=["\']([^"\']*)', page_content)
        cta = self._clean_text(cta_matches[0][0] or cta_matches[0][1]) if cta_matches else None
        
        # Extract body snippet (p tags near the top)
        body_match = re.search(r'<p[^>]*>(.*?)</p>', page_content, re.DOTALL)
        body_snippet = self._clean_text(body_match.group(1)) if body_match else None
        
        return ScrapedCopy(
            url=url,
            headline=headline,
            body_snippet=body_snippet,
            cta=cta
        )
    
    def _clean_text(self, text):
        """Clean extracted text by removing HTML tags and normalizing whitespace"""
        if not text:
            return None
            
        # Remove remaining HTML tags
        text = re.sub(r'<[^>]*>', '', text)
        
        # Normalize whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def analyze_copy_trends(self, scraped_data):
        """Analyze trends in scraped copy"""
        # Count word frequencies in headlines
        headline_words = {}
        for item in scraped_data:
            if item.headline:
                for word in item.headline.lower().split():
                    if len(word) > 3:  # Skip short words
                        headline_words[word] = headline_words.get(word, 0) + 1
        
        # Find common CTAs
        cta_phrases = {}
        for item in scraped_data:
            if item.cta:
                cta_phrases[item.cta] = cta_phrases.get(item.cta, 0) + 1
        
        return {
            'common_headline_words': sorted(headline_words.items(), key=lambda x: x[1], reverse=True)[:10],
            'common_ctas': sorted(cta_phrases.items(), key=lambda x: x[1], reverse=True)[:5]
        }
```

2. Implement more sophisticated HTML parsing using BeautifulSoup if needed
3. Add functionality to extract pricing information when available
4. Create methods to identify common phrases and selling points
5. Implement export functionality for scraped copy insights

# Test Strategy:
Test scraping with sample HTML content. Verify extraction of headlines, CTAs, and body text. Test with various HTML structures. Ensure error handling for failed requests. Test trend analysis with multiple pages. Verify cleaning of HTML tags works correctly.
